## 网络分层

网络的七层结构及其作用，自上而下是：

- 应用层（数据）：为用户的应用程序提供网络服务访问接口。常见的应用层协议包括HTTP、FTP、SMTP、POP3、IMAP、DNS、DHCP、Telnet、SSH、SNMP等。

- 表示层（数据）：负责数据的格式转换、加解密等。

- 会话层（数据）：负责建立、管理和终止会话。它。

- 传输层（段）：为两台主机上的应用程序提供端到端的通信服务，确保数据的可靠传输或提供简单的无连接服务。协议：TCP、UDP。
  
- 网络层（包）：负责数据的路由和转发，将数据包从源主机传输到目标主机。协议：TCP。
  - **设备**：路由器是网络层的关键设备。路由器根据路由表决定数据包的转发路径。

- 数据链路层（帧）：将物理层接收到的原始比特流组合成帧，实现节点间的可靠数据传输，包括差错检测与纠正、流量控制等。
  - **设备**：数据链路层的设备包括交换机和网桥。在以太网中，以太帧有目标MAC地址、源MAC地址、类型等字段。在发送方，链路层将IP包封装成以太帧；在接收方，链路层从以太帧中提取IP包。

- 物理层（比特流）：传输原始比特流。
  - **设备**：电缆、集线器、中继器等。

TCP/IP协议分为以下四层：

- 应用层

- 传输层
- 网络层
- 网络接口层

## TCP 协议

TCP/IP 协议包括两个部分：传输控制协议（TCP）和互联网协议（IP）。IP 协议负责数据包在网络中的传输，而TCP协议则负责在数据传输过程中对数据的可靠性进行保证，确保数据能够被正确地传输到目的地。

### TCP 为什么需要三次握手？

第一次握手：

- 客户端向服务器发送一个带有 SYN 标志位的数据段，请求建立连接，同时携带一个初始序列号（seq = x）。
- 客户端进入 SYN-SENT 状态，等待服务器的响应。

第二次握手：

- 服务器收到客户端的 SYN 请求后，回送一个带有 SYN 和 ACK 标志位的数据段，其中 ACK 应答号为 x + 1，并携带自己的初始序列号（seq = y）。

- 服务器处于 SYN-RCVD 状态

第三次握手：

- 客户端收到服务器的 SYN + ACK 数据段后，发送一个带有 ACK 标志位的数据段，其中应答号为 y + 1，确认收到服务器的响应。
- 客户端和服务器都进入 ESTABLISHED 状态

![image-20250304170937078](assets/image-20250304170937078.png)



TCP 协议在建立连接时采用三次握手的方式，主要是为了确保客户端和服务器双方在建立连接时都能够准确同步并确认对方的存在和状态。 **TCP 之所以需要 3 次握手是因为 TCP 双方都是全双工的**。

所谓全双工指的是，TCP 任何一端既是发送数据方，又是接收数据方，因此这就要求 TCP 通讯双方既要保证自己的发送能力，又要保证自己的接收能力才行。

以下是为什么两次握手不够的原因：

1. **无法区分重复请求**

- 如果只有两次握手，客户端发送一个 `SYN` 请求后，服务器发送一个 `ACK` 响应。但如果这个 `ACK` 响应返回到客户端时，客户端网络出现故障，或者客户端没有收到响应，客户端会重新发送 `SYN` 请求。如果服务器没有一个机制来确认客户端确实已经接收到它的响应，就会导致无法区分哪些是重复的请求，从而可能建立重复的连接。

2. **无法确认双方都准备好**

- 三次握手可以确保双方都准备好进行通信。第一次握手（客户端发送 `SYN`）表示客户端想要建立连接，第二次握手（服务器发送 `SYN+ACK`）表示服务器同意建立连接并且已经准备好接收数据，第三次握手（客户端发送 `ACK`）表示客户端确认了服务器的响应并且也准备好发送数据。如果只有两次握手，服务器无法确认客户端是否已经准备好接收数据，从而可能导致数据丢失或混乱。

3. **无法避免旧连接的干扰**

- 网络中可能存在延迟的数据包，这可能导致旧的连接请求在新连接建立时被误认为是新的请求。通过三次握手，可以确保双方都使用最新的序列号和确认号，从而避免旧连接的干扰。

4. **无法确保数据传输的可靠性**

- TCP 是一个面向连接的协议，旨在提供可靠的数据传输。三次握手是 TCP 可靠性的一部分，它可以确保在连接建立之前，双方都已经同步了初始序列号和其他重要参数，从而为后续的数据传输提供了一个可靠的通信通道。

5. **无法确保数据包的顺序和完整性**

- 在三次握手中，双方可以协商和确认初始序列号。这些序列号用于确保数据包的顺序和完整性。如果只有两次握手，序列号的协商可能无法正确完成，从而导致数据传输的混乱。



### TCP 为什么需要四次挥手？

四次挥手，简单来说，就是：

发送方：我要和你断开连接！

接收方：好的，断吧。

接收方：我也要和你断开连接！

发送方：好的，断吧。



TCP 四次挥手是 TCP 协议中用于终止连接的一个过程，具体如下：

第一次挥手：

- 主动关闭方（假设为客户端）发送一个带有 FIN 标志位的数据段，请求释放连接，此时客户端停止发送数据，但还会继续接收数据，同时携带一个序列号（seq = u）。

- 客户端进入 FIN-WAIT-1 状态

第二次挥手：

- 服务器收到客户端的 FIN 请求后，发送一个带有 ACK 标志位的数据段，应答号为 u + 1，确认收到客户端的 FIN 请求，此时服务器开始处理关闭连接的准备工作，但还可以继续发送数据给客户端。

- 此时，服务器进入 CLOSE-WAIT 状态，而客户端进入 FIN-WAIT-2 状态。

第三次挥手：

- 服务器完成关闭准备后，发送一个带有 FIN 标志位的数据段，同时携带一个序列号（seq = v），请求客户端确认关闭连接。

- 此时，服务器进入 LAST-ACK 状态。

第四次挥手：

- 客户端收到服务器的 FIN 请求后，发送一个带有 ACK 标志位的数据段，应答号为 v + 1，确认收到服务器的 FIN 请求，至此，TCP 连接被完全关闭，双方停止通信。

- 此时，客户端进入 TIME-WAIT 状态，服务器进入 CLOSED 状态。客户端会在等待一段时间后，确认服务器已收到 ACK，然后关闭连接进入 CLOSED 状态。



![image-20250304170921630](assets/image-20250304170921630.png)

四次挥手的主要作用是：

1. 确保所有数据都被传输完成：在关闭连接前，双方都可能还有数据需要传输，因此需要四次挥手来确保所有数据都被传输完成。
2. 避免服务器收到来自已关闭的连接的数据：在关闭连接后，服务器可能会收到来自已关闭的连接的数据，因此需要等待一段时间，确保客户端收到了服务器的 FIN 包并确认关闭连接，才能关闭连接。
3. 确保双方都能正确地关闭连接：四次挥手的过程中，客户端和服务器都需要发送 FIN 和 ACK 包，以确保双方都能正确地关闭连接，避免连接一方关闭而另一方仍然处于连接状态。

因此，TCP 协议需要进行四次挥手，以确保双方都能正确地关闭连接，并避免数据的丢失和混淆。



**为什么要有TIME_WAIT状态？**

TIME_WAIT状态存在有两个原因。

一、可靠终止TCP连接。如果最后一个ACK报文因为网络原因被丢弃，此时server因为没有收到ACK而超时重传FIN报文，处于TIME_WAIT状态的client可以继续对FIN报文做回复，向server发送ACK报文。

二、保证让迟来的TCP报文段有足够的时间被识别和丢弃。连接结束了，网络中的延迟报文也应该被丢弃掉，以免影响立刻建立的新连接。

### TCP粘包、拆包及解决办法

一、什么是TCP粘包和拆包

**TCP粘包**是指在TCP传输过程中，发送方将多个数据包合并成一个大的数据包发送，接收方在接收时无法区分每个数据包的边界，导致数据包粘连在一起。例如，发送方发送了两个数据包“Hello”和“World”，但由于网络延迟或缓冲区大小的原因，这两个数据包被合并成一个数据包“HelloWorld”发送到接收方，接收方在读取时就会出现粘包问题。

**TCP拆包**是指在TCP传输过程中，发送方将一个大的数据包拆分成多个小的数据包发送，接收方在接收时需要将这些小的数据包重新组装成一个完整的数据包。例如，发送方发送了一个很长的字符串，但由于网络阻塞等原因，发送方将该字符串拆分成多个小的数据包发送，接收方在接收时需要将这些小的数据包重新组装成一个完整的字符串。

二、为什么会产生TCP粘包和拆包

TCP是一个面向连接的、可靠的、基于字节流的传输层通信协议。它并不保证消息的边界，因此在传输过程中可能会出现粘包和拆包的现象。具体原因如下：

1. **TCP缓冲区**：TCP在传输数据时，会将数据放入缓冲区中，当缓冲区满时，会将数据发送出去。如果发送方发送的数据量较小，可能会被合并成一个大的数据包发送，导致粘包。
2. **网络延迟**：网络延迟可能导致数据包在传输过程中被合并或拆分，从而导致粘包和拆包。
3. **应用层协议**：应用层协议没有明确的消息边界，导致接收方无法准确区分每个数据包的边界。

三、解决TCP粘包和拆包的方法

1. **固定数据大小**：发送方在发送数据时，每个数据包都固定长度，如果数据长度不足，则通过补充空格的方式补全到指定长度。接收方按照固定的长度读取数据，从而避免粘包和拆包的问题。
2. **自定义请求协议**：将消息分为头部和消息体，在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息。
3. **特殊字符结尾**：在每个数据包的末尾添加一个特殊的字符，如`\n`，接收方根据这个特殊字符来识别数据包的边界。
4. **禁止Nagle算法**：Nagle算法会导致TCP缓存中存在小的数据包，当多个数据包同时到达时就会出现粘包问题。可以设置`TCP_NODELAY`选项禁用Nagle算法，即每个输出数据报只要有数据都立刻就发出去，反之则等待到缓存区满或超时才发送
5. **基于应用层协议**：使用现有的应用层协议（如HTTP、Protobuf、JSON-RPC等）来处理消息边界，通常这些协议已经定义了自己的消息格式和解析方式

## UDP 协议

UDP（User Data Protocol，用户数据报协议），是与 TCP 相对应的协议。它是面向非连接的协议，它不与对方建立连接，而是直接就把数据包发送过去。

UDP协议的主要特点：

1. **无连接**：UDP在发送数据前不需要建立连接，发送结束时也没有连接可以释放。这减少了开销和发送数据之前的时延。
2. **不可靠传输**：UDP不保证数据的可靠交付，因此主机不需要维持复杂的连接状态。这种方式称为“尽最大努力交付”（Best-Effort Delivery）。
3. **面向报文**：UDP对应用层交下来的报文，在添加首部后就向下交付给IP层，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文。
4. **无拥塞控制**：UDP没有拥塞控制机制，适合用于对实时性要求较高、可以容忍一定数据丢失的应用场景，如IP电话、实时视频会议等。
5. **支持一对一、一对多、多对一和多对多的交互通信**。
6. **首部开销小**：UDP只有8个字节的首部开销，相对于TCP的20个字节信息包的额外开销要小得多。



### UDP 与 TCP 的区别

UDP与TCP的区别主要体现在以下几个方面：

1. **连接性**：
   - TCP是面向连接的协议，需要在数据传输前通过三次握手建立连接，并在结束后通过四次挥手关闭连接。
   - UDP是无连接的，发送和接收数据报文时不需要预先建立或关闭连接。
2. **可靠性**：
   - TCP提供可靠的传输服务，使用确认应答、序列号、重传控制等机制来保证数据的正确传递。此外，TCP还实现了流量控制和拥塞控制，以防止网络过载和丢包。
   - UDP不保证数据的可靠性，没有顺序、错误检查或重传机制。
3. **头部开销**：
   - TCP的首部通常有20个字节，包含许多控制信息，如序列号、确认响应号等，这些额外的信息增加了TCP的开销。
   - UDP具有更小的头部开销，只有8个字节，因此传输效率更高。
4. **传输效率**：
   - 由于TCP的复杂控制机制，其传输效率相对较低。
   - UDP无需建立连接或处理重传，因此传输效率更高。但这也意味着可能会丢失数据。
5. **应用场景**：
   - TCP常用于需要可靠传输的场景，如Web页面加载、文件传输、电子邮件等。
   - UDP适用于实时应用，如视频会议、在线游戏，这些场景能够容忍一定程度的数据丢失。
6. **通信模式**：
   - TCP只支持一对一的点对点通信。每个TCP连接仅支持一个发送方和一个接收方。
   - UDP支持一对多、多对一和多对多的通信模式，可以实现广播和组播功能。

## DNS

### DNS 域名解析流程

1. 先检**查浏览器中的 DNS 缓存**，如果浏览器中有对应的记录会直接使用，并完成解析；

2. 如果浏览器没有缓存，那就去**查询操作系统的缓存**，如果查询到记录就可以直接返回 IP 地址，完成解析；

3. 如果操作系统没有 DNS 缓存，就会去**查看本地 host 文件**
4. 如果本地 host 文件没有相应的记录，会**请求本地 DNS 服务器**，本地 DNS 服务器一般是由本地网络服务商如移动、电信提供。通常情况下可通过 DHCP 自动分配，当然你也可以自己手动配置。
5. 如果本地 DNS 服务器没有相应的记录，就会**去根域名服务器查询**了，目前全球一共有 13 组根域名服务器（这里并不是指 13 台服务器，是指 13 个 ip 地址，按字母 a-m 编号），为了能更高效完成全球所有域名的解析请求，根域名服务器本身并不会直接去解析域名，而是会把不同的解析请求分配给下面的其他服务器去完成。

### DNS 查询

DNS 查询是域名解析服务中的关键步骤，它指的是本地域名服务器向其他 DNS 服务器发送请求，以获取特定域名的 IP 地址。DNS 查询分为递归查询和迭代查询两种方式：

1. 递归查询：本地域名服务器向其他 DNS 服务器发送 DNS 查询请求，并要求对方返回域名的 IP 地址。如果对方无法返回 IP 地址，则继续向更高级别的 DNS 服务器发送查询请求，直到查询到最终的 IP 地址为止。
2. 迭代查询：本地域名服务器向其他 DNS 服务器发送 DNS 查询请求，对方只返回指向下一级 DNS 服务器的 IP 地址，本地域名服务器再向该下一级服务器发送查询请求，直到查询到最终的IP地址为止。

DNS 查询的过程中，本地域名服务器会优先查询自己的缓存中是否有该域名的 IP 地址记录，如果有则直接返回给用户；如果没有，则会向其他 DNS 服务器发送查询请求，获取该域名的 IP 地址。DNS 查询过程中，为了提高查询效率，本地域名服务器会采用以下两种方式：

1. DNS 负载均衡：本地域名服务器会通过轮询或随机分配的方式，将查询请求分发到多个 DNS 服务器中，以达到负载均衡的效果。
2. DNS 缓存：本地域名服务器会将查询过的域名和其对应的 IP 地址记录在缓存中，以便于下一次查询时直接从缓存中返回 IP 地址，提高查询效率。

## HTTP 协议

### URL 执行流程

1. **对请求地址进行解析**
   1. 解析协议。浏览器会根据协议类型来决定采用何种方式获取资源。
   2. 对域名进行 DNS 解析，获取服务器 IP。
   3. 解析端口号
   4. 解析路径
   5. 解析查询字符串
   6. 解析锚点


2. **建立 TCP 连接**

- **目的**：与目标服务器建立可靠的网络连接。
- **过程**：
  1. 浏览器使用解析得到的 IP 地址，通过 TCP 协议向目标服务器发起连接请求（SYN 包）。
  2. 服务器收到请求后，会回复一个 SYN-ACK 包，表示同意建立连接。
  3. 浏览器再发送一个 ACK 包，确认连接建立。至此，TCP 三次握手完成，连接建立成功。

3. **发送 HTTP 请求**

- **目的**：向服务器请求指定的资源。
- **过程**：
  1. 浏览器通过已建立的 TCP 连接，向服务器发送 HTTP 请求。请求中包含请求方法（如 GET、POST）、请求头（如 Host、User-Agent、Accept 等）和请求体（对于 POST 请求）。
  2. 请求方法：通常使用 GET 方法获取资源，使用 POST 方法提交数据。
  3. 请求头：包含客户端信息、请求内容类型等。
  4. 请求体：对于 POST 请求，包含要提交的数据。

4. **服务器处理请求**

- **目的**：服务器根据请求内容，处理并返回响应。
- **过程**：
  1. 服务器接收到 HTTP 请求后，根据请求方法和 URL，确定要处理的资源或服务。
  2. 服务器可能需要查询数据库、调用后端服务或执行其他业务逻辑来处理请求。
  3. 服务器将处理结果封装成 HTTP 响应，包含状态码（如 200 表示成功，404 表示未找到等）、响应头（如 Content-Type、Content-Length 等）和响应体（如 HTML 页面、JSON 数据等）。

5. **接收 HTTP 响应**

- **目的**：浏览器接收服务器返回的响应，并进行处理。
- **过程**：
  1. 浏览器通过 TCP 连接接收服务器返回的 HTTP 响应。
  2. 浏览器解析 HTTP 响应，根据状态码判断请求是否成功。
  3. 如果请求成功，浏览器会根据响应头中的 Content-Type 等信息，对响应体进行相应的处理。例如，如果是 HTML 页面，浏览器会解析并渲染页面；如果是 JSON 数据，浏览器可能会将其解析为 JavaScript 对象。

6. **渲染页面**

- **目的**：将接收到的资源展示给用户。
- **过程**：
  1. 如果响应是 HTML 页面，浏览器会解析 HTML 文档，构建 DOM 树。
  2. 浏览器会根据 CSS 样式和 JavaScript 脚本，对页面进行渲染和交互处理。
  3. 如果页面中包含其他资源（如图片、CSS 文件、JavaScript 文件等），浏览器会根据这些资源的 URL，再次发起 HTTP 请求获取并加载它们。

7. **关闭连接**

- **目的**：释放网络资源。
- **过程**：
  1. 浏览器和服务器完成数据传输后，会根据 HTTP 协议的 Keep-Alive 机制决定是否关闭连接。
  2. 如果连接需要关闭，浏览器和服务器会通过 TCP 四次挥手过程，关闭连接。

### 生产Nginx现大量TIME-WAIT 的原因是什么？

1. **短连接导致的 TIME-WAIT**

- **原因**：Nginx 与后端服务器之间使用的是 HTTP 短连接（HTTP/1.0 或 HTTP/1.1 未启用 Keep-Alive）。每次请求完成后，连接会被主动关闭，导致大量 TIME-WAIT 状态的连接。

- **解决方案**：

  - **启用 HTTP Keep-Alive**：在 Nginx 配置中启用 `proxy_http_version 1.1;` 和 `proxy_set_header Connection "";`，以启用 HTTP/1.1 的 Keep-Alive 功能，减少连接的建立和关闭次数。

    ```nginx
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
    ```

  - **配置 Upstream Keep-Alive**：在 Nginx 的 upstream 模块中配置 `keepalive` 参数，设置可复用的 TCP 连接的空闲数量的最大值，以减少连接的创建和销毁。

    ```nginx
    upstream backend {
        server backend_server:80;
        keepalive 50;
    }
    ```

2. **高并发请求导致的 TIME-WAIT**

- **原因**：在高并发场景下，Nginx 与后端服务器之间的连接频繁建立和关闭，导致 TIME-WAIT 状态的连接数量迅速增加。

- **解决方案**：

  - **增加 Keep-Alive 请求次数**：调整 Nginx 的 `keepalive_requests` 参数，增加每个 Keep-Alive 连接可以处理的请求数量，减少连接的关闭频率。

    ```nginx
    http {
        keepalive_requests 1000;
    }
    ```

  - **优化后端服务器配置**：确保后端服务器也支持 HTTP Keep-Alive，并配置合理的超时时间，避免连接过早关闭。

3. **后端服务器主动关闭连接**

- **原因**：后端服务器在处理完请求后主动关闭连接，导致 Nginx 作为客户端进入 TIME-WAIT 状态。
- **解决方案**：
  - **检查后端服务器配置**：确保后端服务器未禁用 HTTP Keep-Alive，并配置合理的超时时间。
  - **调整后端服务器超时时间**：增加后端服务器的超时时间，避免连接过早关闭。

4. **网络问题导致的连接超时**

- **原因**：网络延迟或不稳定导致连接超时，Nginx 会主动关闭连接，进入 TIME-WAIT 状态。
- **解决方案**：
  - **优化网络环境**：检查网络设备和线路，确保网络稳定。
  - **调整超时时间**：增加 Nginx 和后端服务器的超时时间，避免因网络波动导致连接过早关闭。

5. **客户端连接超时**

- **原因**：客户端在请求完成后未及时关闭连接，导致 Nginx 与后端服务器之间的连接保持时间过长，最终进入 TIME-WAIT 状态。

- **解决方案**：

  - **设置客户端超时时间**：在 Nginx 中设置 `client_body_timeout` 和 `client_header_timeout` 参数，确保客户端在规定时间内完成请求。

    ```nginx
    http {
        client_body_timeout 60;
        client_header_timeout 60;
    }
    ```

6. **系统参数配置不当**

- **原因**：系统参数如 `tcp_fin_timeout` 设置过长，导致 TIME-WAIT 状态的连接保持时间过长。

- **解决方案**：

  - **调整系统参数**：修改 `/proc/sys/net/ipv4/tcp_fin_timeout` 文件，将 TIME-WAIT 状态的持续时间缩短。

    ```bash
    echo 30 > /proc/sys/net/ipv4/tcp_fin_timeout
    ```

  - **优化 TCP 参数**：调整 `net.ipv4.tcp_tw_reuse` 和 `net.ipv4.tcp_tw_recycle` 参数，启用 TIME-WAIT 状态连接的重用和快速回收。

    ```bash
    sysctl -w net.ipv4.tcp_tw_reuse=1
    sysctl -w net.ipv4.tcp_tw_recycle=1
    ```

### Http与Https区别

HTTP 的URL 以http:// 开头，而HTTPS 的URL 以https:// 开头

HTTP 是不安全的，而 HTTPS 是安全的

HTTP 标准端口是80 ，而 HTTPS 的标准端口是443

在OSI 网络模型中，HTTP工作于应用层，而HTTPS 的安全传输机制工作在传输层

HTTP 无法加密，而HTTPS 对传输的数据进行加密

HTTP无需证书，而HTTPS 需要CA机构颁发的SSL证书

### HTTP优化方案

一、协议升级

- **升级到HTTP/2或HTTP/3**：HTTP/2引入了多路复用、头部压缩等特性，显著减少了连接建立时间和数据传输量。HTTP/3则进一步基于QUIC协议，提供了更好的连接恢复机制和更低的延迟。升级Web服务器以支持HTTP/2或HTTP/3，并正确配置。启用ALPN（Application-Layer Protocol Negotiation）以加快TLS握手过程中的协议选择。

二、内容分发网络（CDN）

- **使用CDN**：通过在全球多个地理位置部署缓存节点，CDN可以缩短用户与资源之间的物理距离，从而加速内容交付。选择合适的CDN服务提供商，如Cloudflare、Akamai等。配置静态资源缓存，将图片、CSS、JavaScript等静态文件托管到CDN上。设置智能路由，根据用户的地理位置自动选择最近的节点进行内容分发。

三、资源优化

- **合并与压缩文件**：在Web开发中，合并CSS和JavaScript文件是减少HTTP请求数量的有效方法。使用工具如Webpack、Gulp等，将多个CSS和JavaScript文件合并成一个文件。对于图片，使用CSS Sprites技术将多个小图片合并成一张大图，利用CSS的`background-position`属性来显示不同的图标。
- **图片优化**：对网站中的图片进行格式转换和压缩，将部分JPEG格式的图片转换为WebP格式，利用其更好的压缩比来减小文件大小。通过服务器端的脚本，根据浏览器的支持情况，动态地为用户提供WebP或JPEG格式的图片。实施图片懒加载和响应式图片技术，为图片添加`loading="lazy"`属性，实现图片懒加载。对于响应式图片，利用`<picture>`标签，根据不同设备的屏幕尺寸和分辨率，提供合适大小的图片资源。

四、缓存策略

- **浏览器缓存**：通过设置合适的HTTP头字段来控制缓存。对于静态资源，如CSS、JavaScript和图片文件，设置`Cache-Control`头字段为`max-age=31536000`（一年），确保这些资源在浏览器中长时间缓存。对于动态变化的资源，如商品库存信息，设置为`no-cache`，确保每次请求都能获取最新数据。
- **服务端缓存**：在服务端，引入Redis作为缓存中间件，将热门商品信息、用户会话信息等缓存起来。通过合理设置缓存过期时间和缓存预热机制，提高缓存命中率，减少数据库的访问压力。

五、请求优化

- **减少或避免重定向**：重定向会增加中间多余请求开销，应尽量减少或避免不必要的重定向。
- **通过不同域请求资源**：一个域下并行下载资源的数目有限，并行数量一般为4-6个。通过使用多个域来请求资源，可以增加并行下载数量，提高加载速度。
- **避免404**：404请求会造成网络请求处理时间较长，占用带宽从而影响其他资源的请求。应确保所有请求的资源都存在，避免404错误。
- **避免img标签等src链接为空**：空的src链接会增加无效请求，应确保img标签等的src链接有效。

六、内容加载与缓存配置

- **优化请求顺序**：优化请求的顺序可以确保关键资源优先加载。在页面加载过程中，应优先加载对用户交互和页面渲染至关重要的资源，如CSS、关键JS脚本等。对于非关键资源，可以采用异步加载或延迟加载的方式，避免阻塞页面渲染。
- **浏览器预取与预加载**：提前告知浏览器即将需要的资源，以便它可以在后台预先获取这些资源，减少实际使用时的等待时间。使用`<link rel="dns-prefetch">`提前解析外部域名，使用`<link rel="preload">`提示浏览器尽早加载重要的资源，使用`<link rel="prerender">`使浏览器在后台开始渲染指定页面。

七、后端处理优化

- **减少后端处理时间**：服务器响应的延迟可能由资源分布、后端逻辑或数据库查询导致。优化数据库查询，使用索引或分布式数据库，减少后端处理时间。
- **启用HTTP/2或HTTP/3协议**：利用多路复用减少连接延迟。





### GET与POST的区别

| 方面         | GET方法                                                      | POST方法                                                     |
| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **语义**     | 用于从服务器获取资源。                                       | 用于向服务器提交数据，通常用于更改服务器上的资源。           |
| **参数传递** | 通过URL传递参数，参数显示在URL中。                           | 通过请求体传递参数，参数不显示在URL中。                      |
| **安全性**   | 不安全，因为参数暴露在URL中，容易被记录和共享。              | 相对安全，参数不在URL中显示，减少了敏感信息被泄露的风险。    |
| **缓存**     | 可以被浏览器和服务端缓存，适合用于获取静态资源。             | 不会被缓存，在每次请求时都会重新发送数据。                   |
| **幂等性**   | 是幂等的，多次相同的GET请求应该返回相同的结果，不会对服务器状态造成影响。 | 不是幂等的，多次相同的POST请求可能会导致数据重复插入或其他副作用。 |
| **限制**     | URL长度有限制（通常为2048个字符），不能传递大量数据。        | 无明显限制，可以传递大量数据。                               |
| **默认行为** | 是大多数浏览器表单的默认方法，适用于简单的数据查询。         | 适用于复杂的数据提交和文件上传。                             |

### Cookie、Session 和 Token 有什么区别？

1. **存储位置**：
   - **Cookie**：存储在客户端，即浏览器中的文本文件。它通过在HTTP头中传递给服务器来进行通信。
   - **Session**：是服务器端的存储方式，通常存储在服务器的内存或数据库中。
   - **Token**：也是存储在客户端，但通常以加密的方式存储在客户端的localStorage或sessionStorage中。
2. **数据安全性**：
   - **Cookie**：由于存储在客户端，可能会被窃取或篡改，因此对敏感信息的存储需要进行加密处理。
   - **Session**：存储在服务器端，通过一个Session ID在客户端和服务器之间进行关联，可以避免敏感数据直接暴露。
   - **Token**：通常使用加密算法生成，有效期较短且单向不可逆，可以提供较高的安全性。
3. **跨域支持**：
   - **Cookie**：为了防止安全事故，Cookie是不支持跨域传输的，即不同域名下的Cookie是不能相互访问的。
   - **Session**：Session机制通常是通过Cookie来保存Session ID的，因此Session ID默认情况下也是不支持跨域的。
   - **Token**：可以轻松实现跨域，因为Token是存储在客户端的localStorage或者作为请求头的一部分发送到服务器的，所以不同的域名Token信息传输通常是不受影响的。
4. **状态管理**：
   - **Cookie**：是应用程序通过在客户端存储临时数据，用于实现状态管理的一种机制。
   - **Session**：是服务器端记录用户状态的方式，服务器会为每个会话分配一个唯一的Session ID，并将其与用户状态相关联。
   - **Token**：是一种用于认证和授权的机制，通常表示用户的身份信息和权限信息。

### HTTP 与 TCP 的区别

1. **定义**

- **HTTP (Hyper Text Transfer Protocol)**：超文本传输协议，是一种在浏览器与Web服务器之间传送超文本的传送协议。
- **TCP (Transmission Control Protocol)**：传输控制协议，是基于连接的协议，用于在网络中传输数据。

2. **作用**

- **HTTP**：用于在浏览器和Web服务器之间进行通信，主要负责请求和响应消息的传输。
- **TCP**：为IP协议提供错误恢复和流量控制，是网络模型中运输层协议，并对上层协议（如HTTP）进行支持。

3. **工作方式**

- **HTTP**：通过请求-响应的方式进行通信。浏览器发送HTTP请求到服务器，服务器处理请求并返回HTTP响应。
- **TCP**：通过建立连接进行数据传输。在传输数据之前，必须先建立一个可靠的连接，数据以数据流的形式传输，并通过序列号和确认号来保证数据的可靠传输。

4. **安全性**

- **HTTP**：是明文传输，容易被窃听。通常会使用 HTTPS（HTTP Secure）来加密传输。
- **TCP**：本身不提供加密功能，但在数据传输的安全性方面，TCP通过三次握手和四次挥手等机制确保了连接的可靠性和数据的完整性。

5. **应用范围**

- **HTTP**：主要用于Web应用，包括网页浏览、图片、视频等资源的传输。
- **TCP**：广泛应用于各种网络通信场景，包括文件传输、电子邮件、远程登录等。

6. **特性**

- **HTTP**：
  - **无状态**：每个请求都是独立的，服务器不会保留客户端的状态信息。
  - **明文传输**：默认情况下，数据以明文形式传输，可以被中间设备读取和修改。
- **TCP**：
  - **面向连接**：在数据传输之前需要建立连接。
  - **可靠传输**：通过确认和重传机制确保数据的可靠传输。
  - **流式传输**：数据以流的形式传输，没有消息边界。

### 请求转发和重定向区别

1. **请求次数**：
   - 请求转发（Request Forwarding）：只涉及一次请求。服务器收到客户端的请求后，为了完成响应，会内部跳转到一个新的地址，但这个过程对客户端是透明的，客户端只发起了一次请求。
   - 重定向（Redirect）：至少涉及两次请求。首先，客户端向服务器发送一个请求，服务器响应后告诉客户端需要重定向到另一个地址，然后客户端再向这个新地址发送第二个请求。
2. **地址栏变化**：
   - 请求转发：地址栏不会发生变化，因为整个转发过程是在服务器端完成的，客户端并不知道发生了跳转。
   - 重定向：地址栏会发生变化，因为客户端收到了服务器返回的重定向指令后，会向新的地址发送请求，地址栏会显示新的URL。
3. **数据共享**：
   - 请求转发：在一次请求中，数据可以在转发的各个页面间共享，通常是在request级别进行信息共享。
   - 重定向：由于涉及到两次独立的请求，因此两次请求之间不共享数据。
4. **跳转限制**：
   - 请求转发：只能跳转到本站点的其他资源，无法跳转到外部站点。
   - 重定向：可以跳转到任意URL，无论是本站点的其他资源还是外部站点。
5. **行为主体**：
   - 请求转发：是服务器端的行为，由服务器根据内部逻辑进行跳转。
   - 重定向：更像是客户端的行为，因为服务器通过响应告诉客户端需要重定向到另一个地址，然后由客户端发起新的请求。

### 什么是 JWT？

JWT（JSON Web Token）是一种开放标准（RFC 7519），用于在网络上安全传输信息的简洁、自包含的方式。它通常被用于身份验证和授权机制。 JWT 由三部分组成：头部（Header）、载荷（Payload）和签名（Signature）。

1. **头部（Header）**：包含了关于生成该 JWT 的信息以及所使用的算法类型。
2. **载荷（Payload）**：包含了要传递的数据，例如身份信息和其他附属数据。JWT 官方规定了 7 个字段，可供使用： 
   1. iss (Issuer)：签发者。
   2. sub (Subject)：主题。
   3. aud (Audience)：接收者。
   4. exp (Expiration time)：过期时间。
   5. nbf (Not Before)：生效时间。
   6. iat (Issued At)：签发时间。
   7. jti (JWT ID)：编号。
3. **签名（Signature）**：使用密钥对头部和载荷进行签名，以验证其完整性。

JWT 相较于传统的基于会话（Session）的认证机制，具有以下优势：

1. **无需服务器存储状态**：传统的基于会话的认证机制需要服务器在会话中存储用户的状态信息，包括用户的登录状态、权限等。而使用 JWT，服务器无需存储任何会话状态信息，所有的认证和授权信息都包含在 JWT 中，使得系统可以更容易地进行水平扩展。
2. **跨域支持**：由于 JWT 包含了完整的认证和授权信息，因此可以轻松地在多个域之间进行传递和使用，实现跨域授权。
3. **适应微服务架构**：在微服务架构中，很多服务是独立部署并且可以横向扩展的，这就需要保证认证和授权的无状态性。使用 JWT 可以满足这种需求，每次请求携带 JWT 即可实现认证和授权。
4. **自包含**：JWT 包含了认证和授权信息，以及其他自定义的声明，这些信息都被编码在 JWT 中，在服务端解码后使用。JWT 的自包含性减少了对服务端资源的依赖，并提供了统一的安全机制。
5. **扩展性**：JWT 可以被扩展和定制，可以按照需求添加自定义的声明和数据，灵活性更高。

## IO模型

### nio和 bio 、aio的区别

BIO（Blocking I/O）

- **定义**：同步阻塞 I/O 模型，是传统 Java I/O 编程模型。
- **工作原理**：服务器端为每个客户端连接创建一个独立的线程来处理请求，线程在 I/O 操作时会阻塞，直到操作完成。
- **优缺点**：
  - **优点**：实现简单，代码直观易懂。
  - **缺点**：在高并发场景下，由于每个连接都需要一个线程，线程的创建和切换会消耗大量资源，导致性能瓶颈。

**NIO（Non-blocking I/O）**

- **定义**：同步非阻塞 I/O 模型，是 Java 1.4 引入的 New I/O。
- **工作原理**：基于通道和缓冲区，使用选择器来管理多个通道，实现异步 I/O 操作，一个线程可以同时处理多个连接。
- **优缺点**：
  - **优点**：适合高并发场景，资源利用率高。
  - **缺点**：实现相对复杂，需要手动处理事件循环和回调，开发者需自己处理线程管理。

**AIO（Asynchronous I/O）**

- **定义**：异步非阻塞 I/O 模型， Java 7 引入的 Asynchronous I/O 。
- **工作原理**：基于事件驱动和回调机制，真正的异步 I/O 。操作发起后不会阻塞线程，可在后台等待 I/O 完成，完成后通知线程处理。
- **优缺点**：
  - **优点**：无需轮询，直接唤醒线程处理事件，效率高。
  - **缺点**：目前支持的操作系统有限，且异步编程模型较难理解，代码复杂。
