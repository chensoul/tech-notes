## 问：为什么使用MQ？MQ的优点

主要是：解耦、异步、削峰、数据分发、分布式事务。

## 问：消息队列有什么优缺点？RabbitMQ有什么优缺点？

优点：解耦、异步、削峰、数据分发、分布式事务。

缺点：

- 系统可用性降低。
- 系统复杂度提高。加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。
- 数据一致性问题。

## 问：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

以下是 ActiveMQ、RabbitMQ、RocketMQ、Kafka 和 Pulsar 在各个方面的详细对比表格：

| 特性/消息队列  | ActiveMQ          | RabbitMQ                       | RocketMQ             | Kafka                      | Pulsar       |
| :------------- | :---------------- | :----------------------------- | :------------------- | :------------------------- | :----------- |
| **单机吞吐量** | 万级              | 万级                           | 十万级+              | 十万到百万级               | 十万级+      |
|                |                   |                                |                      |                            |              |
|                |                   |                                |                      |                            |              |
|                |                   |                                |                      |                            |              |
| **负载均衡**   | 是                | 否                             | 否                   | 否                         | 否           |
| **订阅形式**   | 点对点、发布-订阅 | Direct、Topic、Headers、Fanout | 基于topic/messageTag | 基于topic                  | 基于topic    |
| **持久化**     | 支持少量堆积      | 支持少量堆积                   | 支持大量堆积         | 支持大量堆积               | 支持大量堆积 |
| **顺序消息**   | 不支持            | 不支持                         | 支持                 | 支持                       | 支持         |
| **性能稳定性** | 好                | 好                             | 一般                 | 较差                       | 好           |
| **集群方式**   | 主-备             | 复制模式                       | 多对Master-Slave     | 天然Leader-Slave无状态集群 | 分布式集群   |
| **管理界面**   | 一般              | 较好                           | 一般                 | 无（第三方Kafka-Manager）  | 较好         |
| **维护成本**   | 中                | 中                             | 中                   | 高                         |              |
| **适用场景**   | 企业级应用、集成  | 灵活的消息路由                 | 高可用性、高吞吐量   | 大数据流处理、日志聚合     |              |

## 问：MQ 有哪些常见问题？如何解决这些问题？

1. 消息丢失

- **原因**：网络中断、服务故障或配置错误。
- **解决方案**：启用持久化存储，确保消息被可靠地保存到磁盘；设置合理的重试机制；使用事务或确认机制以保证消息传递成功。

2. 重复消费

- **原因**：消费者处理失败后重新消费同一消息。
- **解决方案**：实现幂等性消费逻辑，即相同的业务操作可以多次执行但只产生一次效果；使用全局唯一ID跟踪每条消息的状态。

3. 消息顺序混乱

- **原因**：多线程并发消费导致消息乱序。
- **解决方案**：对于需要保持顺序的消息，可以使用有序队列或分区；限制单个消费者的并发度，确保按顺序处理。

4. 消息堆积

- **原因**：消费者处理速度过慢，或者消费者故障、延迟，无法及时处理消息，导致消息堆积。
- **解决方案**：增加消费者的数量，提高消费的处理速度；优化消费者处理逻辑，提高吞吐量；增加 MQ 的服务器资源，提高 MQ 处理能力；通过分区队列将消息分散到多个队列中，提高整体的处理能力。

5. 数据一致性问题

- **原因**：消息消费者处理失败，导致数据不一致。
- **解决方案**：增加重试机制，可以采用同步重试或异步重试；实现幂等性消费逻辑，确保重复消费不会影响数据一致性；增加对账机制，定期检查数据一致性。



## 问：说说设计MQ思路？

MQ设计的基本目标

- **确定MQ的用途**：明确MQ是用于系统间的通信、解耦、异步任务处理、削峰填谷还是其他场景。
- **设定性能指标**：如吞吐量、延迟、存储容量等，根据业务需求确定MQ需要达到的性能标准。
- **考虑可靠性需求**：确定消息是否需要持久化、是否需要支持事务、是否需要提供确认机制等可靠性的要求。



### 问：多个MQ如何选型？

**RabbitMQ**

erlang开发，对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。每秒钟可以处理几万到十几万条消息。

**RocketMQ**

java开发，面向互联网集群化 ，功能丰富，对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，每秒钟大概能处理几十万条消息。

**Kafka**

Scala开发，面向日志 ，功能丰富，性能最高。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。

**ActiveMQ**

java开发，简单，稳定，性能不如前面三个。不推荐。

## RabbitMQ

### 问：什么是RabbitMQ？

RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件

### 问：rabbitmq 的使用场景

解耦、异步、削峰、数据分发、分布式事务

### 问：RabbitMQ基本概念

Broker： 简单来说就是消息队列服务器实体

Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列

Queue： 消息队列载体，每个消息都会被投入到一个或多个队列

Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来

Routing Key： 路由关键字，exchange根据这个关键字进行消息投递

VHost： vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的

queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。

Producer： 消息生产者，就是投递消息的程序

Consumer： 消息消费者，就是接受消息的程序

Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务

由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。

### 问：RabbitMQ的工作模式

1. **简单队列模式**

- **工作原理**：生产者将消息发送到队列，消费者从队列中接收消息。在这种模式下，一个生产者将消息发送到一个队列，而一个消费者从队列中获取消息。
- **适用场景**：适合简单的一对一通信场景，例如一个生产者和一个消费者之间进行消息传递。

2. **发布-订阅模式**

- **工作原理**：生产者将消息发送到交换机，订阅者（消费者）订阅该交换机。交换机将消息广播给所有订阅的消费者。
- **适用场景**：适用于需要将消息广播给多个订阅者的情景，如新闻发布系统等。

3. **路由模式**

- **工作原理**：生产者将消息发送到交换机时，可以指定路由键（routing key）。消费者在订阅队列时，也会指定一个绑定键（binding key）。交换机根据路由键和绑定键的匹配情况，来决定消息的去向。
- **适用场景**：适用于需要对消息进行分类处理的场景，可以通过路由键把消息转到不同的队列。

4. **通配符模式**

- **工作原理**：路由模式的一种扩展。在绑定键中可以使用通配符（如 `*` 和 `#`）。其中，`*` 匹配一个单词，`#` 匹配零个或多个单词。
- **适用场景**：适用于需要更灵活的消息路由规则的场景，如消息系统、日志处理等。

5. **RPC（远程过程调用）模式**

- **工作原理**：客户端将一个请求消息发送到服务端的消息队列，服务端处理请求后，将结果作为一个响应消息发送回客户端的消息队列。客户端在发送请求时会创建一个临时的回复队列，并告诉服务端使用该队列来返回结果。
- **适用场景**：适用于需要像远程过程调用一样同步获取结果的场景。

### 问：如何保证RabbitMQ消息的顺序性？

1. 单一生产者与单一消费者

- **单一生产者**：确保消息发送端只有一个生产者，这样可以保证消息发送的顺序性。生产者按照顺序发送消息到 RabbitMQ 队列中，RabbitMQ 会按照先进先出的原则存储消息，从而保证消息在队列中的顺序。
- **单一消费者**：确保消息消费端只有一个消费者，这样可以避免多个消费者并发消费消息导致的顺序错乱。消费者按照队列中的顺序依次消费消息，从而保证消息消费的顺序性。

2. 队列锁定

- **设置队列锁定**：RabbitMQ 提供了队列锁定的功能，可以通过在队列上设置一个唯一的消费者密钥来实现。当消费者连接到队列时，需要提供一个唯一的消费者密钥。如果多个消费者使用相同的消费者密钥连接到同一个队列，它们将共享同一个消费索引，并按照发送顺序消费消息。

3. 消息的唯一标识符和重排序逻辑

- **使用消息的唯一标识符**：为每条消息生成一个唯一的业务 ID，消费者在消费消息时，可以根据这个 ID 到数据库或缓存中查询是否已经处理过该消息。如果已经处理过，则跳过；如果没有处理过，则进行处理并记录该 ID，从而保证消息处理的顺序性。
- **实现重排序逻辑**：消费者在接收到消息后，可以先将消息放入一个本地队列中，然后按照消息的顺序对本地队列进行排序，再依次处理排序后的消息。

4. 优先级队列

- **设置消息优先级**：RabbitMQ 支持优先级队列，可以根据消息的优先级来决定消息的处理顺序。为需要优先处理的消息设置较高的优先级，这样这些消息会优先被消费者消费，从而在一定程度上保证消息的顺序性。

5. 延迟队列

- **使用延迟队列**：将一些不太重要的消息设置为较长的延迟时间，将重要消息设置为较短的延迟时间或不设置延迟时间。这样，重要消息会先被消费，从而保证了重要消息的优先处理顺序。

6. 避免消息重排

- **避免消费者异常**：确保消费者在处理消息时不会出现异常，如果出现异常，需要有相应的错误处理机制，如重试、死信队列等，避免消息因为消费者异常而被重新投递，导致消息顺序错乱。
- **合理设置消费者数量**：根据业务需求合理设置消费者的数量，避免因为消费者过多导致消息被并发消费，从而影响消息的顺序性。

7. 消息确认机制

- **手动确认消息**：关闭 RabbitMQ 的自动确认消息功能，消费者在成功处理完消息后，手动发送确认消息给 RabbitMQ。这样，如果消费者在处理消息时出现异常，RabbitMQ 会将消息重新投递给其他消费者，从而避免消息丢失，保证消息的顺序性。

8. 合理设计队列和消费者

- **一个队列一个消费者**：对于需要保证顺序性的消息，可以为每个队列配置一个消费者，这样可以避免多个消费者并发消费消息导致的顺序错乱。
- **多个队列多个消费者**：如果业务需要增加并发度，可以将消息分发到多个队列中，每个队列对应一个消费者。这样，不同队列之间的消息可以并发处理，而每个队列内部的消息仍然可以保证顺序性。

9. 使用事务机制

- **开启事务**：在发送消息或消费消息时，可以开启事务，确保消息的发送和消费是原子操作。如果在发送或消费过程中出现异常，可以回滚事务，避免消息丢失或重复消费，从而保证消息的顺序性。

10. 消息幂等性

- **保证消息幂等性**：即使消息被重复消费，也不会对业务产生影响。可以通过在消息中添加唯一标识符，消费者在处理消息前检查该标识符是否已经处理过，如果已经处理过则跳过，从而避免重复处理消息。

11. 消息不丢失

- **生产者端**：开启确认模式，确保消息发送成功。如果发送失败，生产者可以重发消息。
- **MQ端**：设置消息持久化，将消息存储到磁盘中，避免 MQ 挂掉导致消息丢失。
- **消费者端**：关闭自动确认消息功能，消费者在成功处理完消息后，手动发送确认消息给 RabbitMQ。这样，如果消费者在处理消息时出现异常，RabbitMQ 会将消息重新投递给其他消费者，从而避免消息丢失。

### 问：RabbitMQ消息如何分发？

若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能。

### 问：RabbitMQ消息怎么路由？

消息提供方->路由->一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；

常用的交换器主要分为一下三种：

fanout：如果交换器收到消息，将会广播到所有绑定的队列上

direct：如果路由键完全匹配，消息就被投递到相应的队列

topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符

### 问：RabbitMQ消息基于什么传输？

由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。

### 问：如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？

发送方确认模式

接收方确认机制

### 问：如何保证RabbitMQ消息的可靠传输？

在 RabbitMQ 中保证消息可靠传输需要从生产者、MQ 服务端、消费者三个环节协同保障，以下是具体实现方案及代码示例：

**一、生产者可靠性保障**

1. **Confirm 确认机制**

开启发送方确认模式，确保消息到达 Broker

```properties
// SpringBoot 配置
 spring.rabbitmq.publisher-confirm-type=correlated
```

异步回调处理确认结果

```java
rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> {
   if (!ack) {
       log.error("消息未到达交换机: {}", cause);
       // 重发或记录补偿日志
   }
});
```

2. **Return 回退机制**

处理无法路由到队列的消息

```java
spring.rabbitmq.publisher-returns=true
rabbitTemplate.setMandatory(true);

rabbitTemplate.setReturnsCallback(returned -> {
   log.error("消息路由失败: {}", returned.getMessage());
   // 补偿处理
});
```

3. **消息持久化**

消息体、交换机、队列必须同时持久化

```java
// 发送持久化消息
MessageProperties props = MessagePropertiesBuilder.newInstance()
   .setDeliveryMode(MessageDeliveryMode.PERSISTENT).build();
rabbitTemplate.convertAndSend(exchange, routingKey, message, props);
```

**二、MQ 服务端保障**

1. **持久化配置**

   声明持久化队列和交换机

```java
@Bean
public Queue orderQueue() {
   return new Queue("order.queue", true); // durable=true
}
@Bean
public DirectExchange orderExchange() {
   return new DirectExchange("order.exchange", true, false);
}
```

2. **镜像队列（高可用）**

通过策略实现跨节点消息复制

```bash
rabbitmqctl set_policy ha-all "^ha." '{"ha-mode":"all"}'
```

3. **Lazy Queue 模式**

减少内存压力，消息直接写入磁盘

```java
Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");
channel.queueDeclare("lazy.queue", true, false, false, args);
```



**三、消费者可靠性保障**

1. **手动 ACK 确认**

   关闭自动确认，业务处理完成后手动提交

```java
spring.rabbitmq.listener.simple.acknowledge-mode=manual

@RabbitListener(queues = "order.queue")
public void handleMessage(OrderMessage message, Channel channel, 
                        @Header(AmqpHeaders.DELIVERY_TAG) long tag) {
   try {
       processOrder(message); // 业务处理
       channel.basicAck(tag, false); // 确认消费
   } catch (Exception e) {
       channel.basicNack(tag, false, true); // 重试
   }
}
```

2. **死信队列（DLX）**

处理重复消费失败的消息

```java
Map<String, Object> args = new HashMap<>();
args.put("x-dead-letter-exchange", "dlx.exchange");
args.put("x-dead-letter-routing-key", "dlx.routingKey");
channel.queueDeclare("order.queue", true, false, false, args);
```

3. **消费幂等性**

- 通过唯一业务标识（如订单号）防重复处理

```java
if (redis.setnx("order:12345", "processing") == 1) {
   processOrder();
} else {
   log.warn("重复消息已忽略");
}
```

**四、全链路监控**

1. **消息轨迹追踪**
   - 通过唯一消息 ID 记录全链路状态

```java
CorrelationData correlationData = new CorrelationData("msg-123");
rabbitTemplate.convertAndSend(exchange, routingKey, message, correlationData);
```

2. **关键指标监控**

监控队列深度、消费延迟、节点状态

```bash
# 通过管理API获取队列状态
curl -u guest:guest http://localhost:15672/api/queues
```

**五、容灾恢复策略**

| 故障场景   | 解决方案                 | 恢复耗时预估 |
| :--------- | :----------------------- | :----------- |
| 单节点宕机 | 镜像队列自动切换         | <30秒        |
| 磁盘损坏   | 从镜像节点恢复数据       | 依赖数据量   |
| 网络分区   | 配置 pause_minority 模式 | 人工介入     |

通过以上机制，可达到 99.99% 的消息可靠性。对于金融级场景，建议结合 RocketMQ 事务消息或 Kafka Exactly-Once 语义实现更高保障。



### 问：RabbitMQ为什么不应该对所有的 message 都使用持久化机制？

RabbitMQ不推荐对所有消息启用持久化机制的主要原因及具体影响如下：

**1. 性能损耗显著**

- **磁盘I/O瓶颈**：消息持久化需完成磁盘写入（刷盘），而磁盘操作速度比内存操作慢10-100倍，导致吞吐量从内存队列的10万+/秒骤降至1万-3万/秒
- **内存占用倍增**：持久化消息需同时驻留内存和磁盘，内存消耗增加约30%-50%
- **延迟波动**：高并发场景下，持久化操作会使消息投递延迟从毫级升至百毫级甚至秒级

**2. 集群风险加剧**

- **消息黑洞问题**：若队列未设置durable=true，即使消息持久化，节点宕机后队列消失导致消息丢失
- **恢复效率低下**：节点重启时需全量加载磁盘消息，百万级消息恢复耗时可达数十分钟
- **存储空间激增**：持久化消息占用磁盘空间是内存的2-3倍（二进制编码+索引开销）

**3. 资源成本上升**

- **SSD硬件依赖**：要达到可接受的持久化性能，需配置高性能SSD，硬件成本增加5-8倍
- **运维复杂度**：需监控磁盘空间、IOPS、RAID状态等指标，维护成本提升40%

**实际应用建议**

| 消息类型      | 持久化策略                  | 典型场景                 |
| :------------ | :-------------------------- | :----------------------- |
| 支付/订单类   | 开启持久化+镜像队列+手动ACK | 电商交易、金融结算       |
| 日志/埋点数据 | 非持久化+内存队列           | 用户行为追踪、系统监控   |
| 实时通讯消息  | 非持久化+TTL+死信队列       | IM聊天、游戏状态同步     |
| 定时任务触发  | 持久化+延迟队列             | 订单超时关闭、优惠券过期 |

**优化折中方案**

- **混合存储**：使用Lazy Queues（RabbitMQ 3.6+），消息先存磁盘再加载到内存
- **分级策略**：核心业务消息持久化，非核心消息通过x-max-length限制队列长度
- **批量提交**：每处理100-200条消息执行一次txCommit，减少磁盘操作频率

**示例配置对比**

```java
// 非持久化高性能配置
channel.queueDeclare("stats_queue", false, false, true, null);  // autoDelete=true
channel.basicPublish("", "stats_queue", null, message.getBytes());

// 持久化高可靠配置
Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");  // 惰性队列
channel.queueDeclare("order_queue", true, false, false, args);
channel.basicPublish("", "order_queue", 
    MessageProperties.PERSISTENT_TEXT_PLAIN,  // 持久化标志
    message.getBytes());
```

实际生产环境中，建议将持久化消息比例控制在20%以内，通过Sentinel等监控工具实时报警消息积压情况，在可靠性和吞吐量之间取得平衡。



### 问：RabbitMQ 的集群如何保证高可用的？

RabbitMQ保证高可用的核心方案是通过镜像集群模式结合负载均衡实现，具体实现逻辑如下：

**一、集群架构设计**

1. **节点类型混合部署**
   - **磁盘节点**（Disc Node）：至少部署1个，用于持久化元数据（队列名称、交换机绑定关系等），防止集群元数据丢失
   - **内存节点**（RAM Node）：部署多个，提升处理性能，但需依赖磁盘节点同步元数据
   - *典型部署*：2个磁盘节点（互为主备）+ N个内存节点
2. **镜像队列机制**
   - 通过策略（Policy）指定队列在多个节点镜像同步
   - 创建队列时应用策略示例：

```bash
rabbitmqctl set_policy ha-all "^ha." '{"ha-mode":"all"}'  # 全节点同步
rabbitmqctl set_policy ha-3 "^order." '{"ha-mode":"exactly","ha-params":3}'  # 指定3节点同步
```

**二、高可用实现原理**

| 机制             | 作用                    | 技术细节                                                     |
| :--------------- | :---------------------- | :----------------------------------------------------------- |
| **元数据同步**   | 防止队列/交换机定义丢失 | 所有节点共享元数据，磁盘节点持久化元数据至硬盘               |
| **消息镜像同步** | 防止消息丢失            | 主队列（Master）自动将消息复制到镜像节点（Slave），GM协议保障数据一致性 |
| **自动故障转移** | 主节点宕机时无缝切换    | 集群选举"资历最老"的镜像节点（最早加入的Slave）成为新Master  |
| **负载均衡**     | 避免单点压力            | HAProxy/Nginx对外暴露虚拟IP，监控节点状态并自动剔除故障节点  |
| **双活容灾**     | 防止整个集群故障        | 跨机房部署镜像集群，结合Shovel/Federation插件实现异地数据同步 |

**三、关键配置步骤**

1. **集群搭建**

```bash
 # 节点加入集群（以第二个节点为例）
 rabbitmqctl stop_app
 rabbitmqctl join_cluster rabbit@node1 --ram  # 加入为内存节点
 rabbitmqctl start_app
```

2. **镜像队列策略**

- 通过管理界面或CLI设置队列同步规则：

```bash
rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all"}' --priority 1
```

3. **负载均衡配置（HAProxy示例）**

```conf
 frontend rabbitmq_front
     bind *:5672
     mode tcp
     default_backend rabbitmq_back

 backend rabbitmq_back
     balance roundrobin
     server node1 192.168.1.101:5672 check inter 5000 rise 2 fall 3
     server node2 192.168.1.102:5672 check inter 5000 rise 2 fall 3
```

4. **Keepalived虚拟IP漂移**

主备HAProxy通过VRRP协议维护虚拟IP，实现客户端无感知故障切换

**四、升级方案对比**

| 方案                 | 优点                 | 缺点                         | 适用场景                |
| :------------------- | :------------------- | :--------------------------- | :---------------------- |
| **镜像队列**         | 兼容性好，配置简单   | 同步性能损耗大，扩展性差     | 中小规模业务            |
| **仲裁队列(Quorum)** | 强一致性，自动选举   | 功能限制多（不支持优先级等） | 金融/政务等高可靠性场景 |
| **Streams模式**      | 高吞吐，支持消息回溯 | 仅RabbitMQ 3.9+支持          | 大数据量日志处理场景    |

**五、注意事项**

1. **网络分区处理**：配置pause_minority模式避免脑裂，或使用rabbitmq-autocluster自动恢复
2. **性能调优**：镜像队列数量不宜过多，避免同步流量压垮网络
3. **监控告警**：监控队列深度、节点内存/磁盘使用率、同步延迟等关键指标
4. **升级兼容性**：集群内所有节点需保持相同Erlang和RabbitMQ版本

通过上述机制，RabbitMQ可实现99.95%以上的可用性。对于超大规模场景，建议采用Kafka或RocketMQ等分布式消息系统。



### 问：如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

**消息延迟与过期失效处理**

1. **TTL+死信队列方案**
   - 设置消息/队列的TTL（过期时间），超时消息自动转入死信队列
   - 消费者监听死信队列处理延迟消息
   - *缺陷*：队列中若存在长TTL消息在前，会阻塞后续短TTL消息（需安装rabbitmq_delayed_message_exchange插件解决）
2. **数据补偿机制**
   - 当消息因过期被清理时，需通过业务系统查询丢失数据
   - 在低峰期（如夜间）重新灌入MQ补发消息

**消息队列满额处理**

| 场景         | 处理策略 | 具体操作                                                     |
| :----------- | :------- | :----------------------------------------------------------- |
| 磁盘即将写满 | 紧急消峰 | ① 临时编写消费者程序快速消费并丢弃消息 ② 后续通过数据补偿恢复丢失消息 |
| 持续高负载   | 存储扩容 | 启用Lazy Queue模式（RabbitMQ 1.8+），消息直接落盘避免内存溢出 |

**百万级消息积压处理流程**

1. **紧急扩容（10倍吞吐量方案）**

   步骤：
   ① 修复消费者故障，停止现有消费服务
   ② 新建10倍partition的临时Topic
   ③ 部署分发程序：将积压消息均匀写入新队列（避免复杂处理）

   ④ 临时征用10倍机器并行消费新队列  

   ⑤ 恢复原始架构

2. **异步化改进**

   提升消费速度：

   - 批量消费（设置consumeMessageBatchMaxSize）
   - 线程池并发处理（IO密集型场景）
   - 消息预取优化（调整prefetchCount）

**预防性措施**

- 监控预警：设置队列长度、消费延迟阈值告警
- 动态扩容：基于K8s实现消费者自动弹性伸缩
- 降级策略：非核心消息直接丢弃（需业务容忍）
- 架构优化：采用RocketMQ自动分片机制替代原生RabbitMQ队列

## Kafka

问：kafka如何实现高吞吐？

Kafka是分布式消息系统，需要处理海量的消息，Kafka的设计是把所有的消息都写入速度低容量大的硬

盘，以此来换取更强的存储能力，但实际上，使用硬盘并没有带来过多的性能损失。kafka主要使用了

以下几个方式实现了超高的吞吐率：

顺序读写；

零拷贝

文件分段

批量发送

数据压缩。

具体来说：

读写文件依赖OS文件系统的页缓存，而不是在JVM内部缓存数据，利用OS来缓存，内存利用率高

sendfile技术（零拷贝），避免了传统网络IO四步流程

支持End-to-End的压缩

顺序IO以及常量时间get、put消息Partition 可以很好的横向扩展和提供高并发处理



问：Kafka如何实现每秒上百万的超高并发写入？掌握好面试给你打满分

Kafka 是高吞吐低延迟的高并发、高性能的消息中间件，在大数据领域有极为广泛的运用。配置良好的Kafka 集群甚至可以做到每秒几十万、上百万的超高并发写入。

- 页缓存技术 + 磁盘顺序写。
  - 在写入磁盘文件的时候，可以直接写入这个 OS Cache 里，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把 OS Cache 里的数据真的刷入磁盘文件中。
  - 另外一个就是 kafka 写数据的时候，它是以磁盘顺序写的方式来写的，不是在文件的随机位置来修改数据。

- 零拷贝技术
  - 直接让操作系统的 Cache 中的数据发送到网卡后传输给下游的消费者，中间跳过了两次拷贝数据的步骤，Socket 缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到 Socket 缓存。

![image-20250221151445435](assets/image-20250221151445435.png)