## 线程的实现

以下是操作系统线程实现方式的整理表格，结合用户级线程（ULT）、内核级线程（KLT）及混合模型的实现机制、优缺点和典型应用：

| **实现方式** | **用户级线程（ULT）**                                        |                    **内核级线程（KLT）**                     | **混合模型**                                                 |
| :----------: | :----------------------------------------------------------- | :----------------------------------------------------------: | :----------------------------------------------------------- |
| **实现机制** | 完全由用户空间的线程库管理，内核无感知                       |      由操作系统内核直接管理，线程调度和切换需进入内核态      | 用户级线程与内核级线程按比例（如N:M）映射，结合两者优势      |
| **调度主体** | 用户态线程库（如POSIX线程库）                                |                         操作系统内核                         | 用户态库管理用户线程，内核管理少量内核线程                   |
|   **优点**   | 1. 线程切换无需内核介入，开销极小 2. 可自定义调度算法3. 跨平台兼容性好 | 1. 支持多核并行执行 2. 线程阻塞不影响同一进程其他线程 3. 调度稳定性高 | 1. 兼具用户级线程的轻量性和内核级线程的并行性 2. 支持大规模并发 |
|   **缺点**   | 1. 无法利用多核（单进程绑定单内核线程） 2. 线程阻塞导致整个进程阻塞 | 1. 线程切换需用户态与内核态切换，开销大 2. 系统线程数量受内核资源限制 | 1. 实现复杂度高 2. 需协调用户态与内核态的调度策略            |
| **典型应用** | 1. 早期Java绿色线程（JDK1.2前） 2. 高性能数据库的用户空间协程 | 1. Windows原生线程 2. Linux轻量级进程（LWP） 3. Java现代线程（JDK1.2后） | 1. Go语言的Goroutine（GMP模型） 2. Solaris操作系统的线程实现 3. NPTL线程库 |



## 线程安全

什么是线程安全呢？当多个线程并发访问某个Java对象（Object）时，无论系统如何调度这些线程， 也不论这些线程如何交替操作， 这个对象都能表现出一致的、 正确的行为， 那么对这个对象的操作是线程安全的。 如果这个对象表现出不一致的、 错误的行为， 那么对这个对象的操作不是线程安全的，发生了线程的安全问题。

- 自增运算不是线程安全的。实际上，一个自增运算符是一个复合操作，至少包括三个JVM指令：“内存取值”“寄存器增加1”“存值到内存”。这三个指令在JVM内部是独立进行的，中间完全可能会出现多个线程并发进行。
- 临界区资源与临界区代码段。临界区资源表示一种可以被多个线程使用的公共资源或共享数据，但是每一次只能有一个线程使用它。一旦临界区资源被占用，想使用该资源的其他线程则必须等待。

如果多个线程在临界区代码段的并发执行结果可能因为代码的执行顺序不同而出现不同的结果，我们就说这时在临界区出现了**竞态条件**问题。

为了避免竞态条件的问题，我们必须保证临界区代码段操作必须具备排他性。这就意味着当一个线程进入Critical Section执行时，其他线程不能进入临界区代码段执行。

在Java中，我们可以使用synchronized关键字同步代码块，对临界区代码段进行排他性保护。此外，还可以使用Lock显式锁实例，或者使用原子变量（Atomic Variables）对临界区代码段进行排他性保护。 

### Java语言中的线程安全

我们可以将Java语言中各种操作共享的数据分为以下五类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。

### 线程安全的实现方法

1.互斥同步

**synchronized**

synchronized关键字经过Javac编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。

根据《Java虚拟机规范》的要求，在执行monitorenter指令时，首先要去尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行monitorexit指令时会将锁计数器的值减一。

一旦计数器的值为零，锁随即就被释放了。如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。

根据以上《Java虚拟机规范》对monitorenter和monitorexit的行为描述，我们可以得出两个关于synchronized的直接推论

- 被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。
- 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。

从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，以避免频繁地切入核心态之中。



**ReentrantLock**

与synchronized相比增加了一些高级功能，主要有以下三项：等待可中断、可实现公平锁及锁可以绑定多个条件。

当JDK 6中加入了大量针对synchronized锁的优化措施，相同的测试中就发现synchronized与ReentrantLock的性能基本上能够持平。

推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized：

- synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized。
- Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放。
- 尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。

**synchronized 和 Lock 区别**

synchronized 可用来修饰普通方法、静态方法和代码块，当一个线程访问一个被 synchronized 修饰的方法或者代码块时，会自动获取该对象的锁，其他线程将会被阻塞，直到该线程执行完毕并释放锁。这样就保证了多个线程对共享资源的操作的互斥性，从而避免了数据的不一致性和线程安全问题。

Lock 是一种线程同步的机制，它与 synchronized 相似，可以用于控制对共享资源的访问。相比于 synchronized，Lock 的特点在于更加灵活，支持更多的操作。 

相比于 synchronized，Lock 的优点在于：

- 粒度更细：synchronized 关键字只能对整个方法或代码块进行同步，而 Lock 可以对单个变量或对象进行同步。
- 支持公平锁：synchronized 不支持公平锁，而 Lock 可以通过构造函数指定锁是否是公平锁。
- 支持多个条件变量：Lock 可以创建多个条件变量，即多个等待队列。

synchronized 和 Lock 主要的区别有以下几个方面：

1. 锁的获取方式：synchronized 是隐式获取锁的，即在进入 synchronized 代码块或方法时自动获取锁，退出时自动释放锁；而 Lock 需要程序显式地获取锁和释放锁，即需要调用 lock() 方法获取锁，调用 unlock() 方法释放锁。
2. 锁的性质：synchronized 是可重入的互斥锁，即同一个线程可以多次获得同一把锁，而且锁的释放也只能由获得锁的线程来释放；Lock 可以是可重入的互斥锁，也可以是非可重入的互斥锁，还可以是读写锁。
3. 锁的粒度：synchronized 是以代码块和方法为单位进行加锁和解锁，而 Lock 可以精确地控制锁的范围，可以支持多个条件变量。
4. 性能：在低并发的情况下，synchronized 的性能优于 Lock，因为 Lock 需要显式地获取和释放锁，而 synchronized 是在 JVM 层面实现的；在高并发的情况下，Lock 的性能可能优于 synchronized，因为 Lock 可以更好地支持高并发和读写分离的场景。

总的来说，synchronized 的使用更加简单，但是在某些场景下会受到性能的限制；而 Lock 则更加灵活，可以更精确地控制锁的范围和条件变量，但是使用起来比较繁琐。需要根据具体的业务场景和性能需求来选择使用哪种锁机制。

2.非阻塞同步

互斥同步面临的主要问题是进行线程阻塞和唤醒所带来的性能开销，因此这种同步也被称为阻塞同步。

解决问题的方式上看，互斥同步属于一种悲观的并发策略，其总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享的数据是否真的会出现竞争，它都会进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁），这将会导致用户态到核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等开销。



随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步（Non-Blocking Synchronization），使用这种措施的代码也常被称为无锁（Lock-Free）编程。



为什么笔者说使用乐观并发策略需要“硬件指令集的发展”？因为我们必须要求操作和冲突检测这两个步骤具备原子性。靠什么来保证原子性？如果这里再使用互斥同步来保证就完全失去意义了，所以我们只能靠硬件来实现这件事情，硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成，这类指令常用的有：

- 测试并设置（Test-and-Set）；
- 获取并增加（Fetch-and-Increment）；
- 交换（Swap）；
- 比较并交换（Compare-and-Swap，下文称CAS）；
- 加载链接/条件储存（Load-Linked/Store-Conditional，下文称LL/SC）。

**CAS**

Java里最终暴露出来的是CAS操作。在JDK 5之后，Java类库中才开始使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供。HotSpot虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了



**ABA 问题**

存在一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那就能说明它的值没有被其他线程改变过了吗？这是不能的，因为如果在这段期间它的值曾经被改成B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA问题”。J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类AtomicStampedReference，它可以通过控制变量值的版本来保证CAS的正确性。不过目前来说这个类处于相当鸡肋的位置，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更为高效。

3.无同步方案

要保证线程安全，也并非一定要进行阻塞或非阻塞同步，同步与线程安全两者没有必然的联系。同步只是保障存在共享数据争用时正确性的手段，如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的。

- 可重入代码（Reentrant Code）：不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等。如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。
- 线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。Java 中使用 ThreadLocal。

### 死锁

死锁（Dead Lock）指的是两个或两个以上的运算单元（进程、线程或协程），互相持有对方所需的资源，导致它们都无法向前推进，从而导致永久阻塞的问题就是死锁。

比如线程 1 拥有了锁 A 的情况下试图获取锁 B，而线程 2 又在拥有了锁 B 的情况下试图获取锁 A，这样双方就进入相互阻塞等待的情况。

死锁的产生需要满足以下 4 个条件：

1. **互斥条件**：指运算单元（进程、线程或协程）对所分配到的资源具有排它性，也就是说在一段时间内某个锁资源只能被一个运算单元所占用。
2. **请求和保持条件**：指运算单元已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它运算单元占有，此时请求运算单元阻塞，但又对自己已获得的其它资源保持不放。
3. **不可剥夺条件**：指运算单元已获得的资源，在未使用完之前，不能被剥夺。
4. **环路等待条件**：指在发生死锁时，必然存在运算单元和资源的环形链，即运算单元正在等待另一个运算单元占用的资源，而对方又在等待自己占用的资源，从而造成环路等待的情况。

只有以上 4 个条件同时满足，才会造成死锁。

死锁的常用解决方案有以下两个：

1. 按照顺序加锁：尝试让所有线程按照同一顺序获取锁，从而避免死锁。
2. 设置获取锁的超时时间：尝试获取锁的线程在规定时间内没有获取到锁，就放弃获取锁，避免因为长时间等待锁而引起的死锁。

有一些工具可以帮助排查死锁问题，常见的工具有以下几个：

1. jstack：可以查看 Java 应用程序的线程状态和调用堆栈，可用于发现死锁线程的状态。
2. jconsole 和 JVisualVM：这些是 Java 自带的监视工具，可以用于监视线程、内存、CPU 使用率等信息，从而帮助排查死锁问题。
3. Thread Dump Analyzer（TDA）：是一个开源的线程转储分析器，可用于分析和诊断 Java 应用程序中的死锁问题。
4. Eclipse TPTP：是一个开源的性能测试工具平台，其中包含了一个名为 Thread Profiler 的工具，可以用于跟踪线程运行时的信息，从而诊断死锁问题。

### 锁优化

JVM 在锁机制上进行了多层次的优化，以降低同步操作的开销并提升并发性能。以下是主要的锁优化技术及其原理和应用场景：

#### **1. 偏向锁（Biased Locking）**

#### **目标**

减少无竞争情况下的同步开销。

#### **原理**

- **初次加锁**：当线程首次获取锁时，JVM 将锁对象头中的标记设为偏向模式，并记录线程 ID。
- **重入检查**：后续该线程进入同步块时，只需检查线程 ID 是否匹配，无需原子操作。
- **撤销偏向**：当其他线程尝试竞争时，撤销偏向模式，升级为轻量级锁。

#### **适用场景**

- 单线程重复访问同步块（如工具类、私有缓存）。
- **注意**：Java 15+ 默认禁用偏向锁（`-XX:-UseBiasedLocking`），因多线程环境下撤销开销可能抵消收益。

#### **2. 轻量级锁（Lightweight Locking）**

#### **目标**

避免重量级锁的线程阻塞开销。

#### **原理**

- **加锁流程**：
  1. 在栈帧中创建锁记录（Lock Record），复制对象头的 Mark Word。
  2. 通过 CAS 将对象头指向锁记录，成功则获取锁。
- **解锁流程**：CAS 将 Mark Word 恢复，若失败说明存在竞争，触发锁膨胀。

#### **适用场景**

- 低竞争环境（如两个线程交替执行）。
- **开销**：CAS 操作失败时升级为重量级锁。

#### **3. 自旋锁与适应性自旋（Adaptive Spinning）**

#### **目标**

减少线程挂起恢复的开销。

#### **原理**

- **自旋锁**：线程在获取锁失败时，执行忙循环（自旋）而非立即挂起。
- **适应性自旋**：根据历史自旋成功率和锁持有时间动态调整自旋次数。

#### **参数控制**

```
-XX:+UseSpinning          # 启用自旋（JDK6前需手动开启，现默认整合）
-XX:PreBlockSpin=10       # 默认自旋次数（适应性自旋下无效）
```

#### **适用场景**

- 锁持有时间短（如计数器递增）。
- **风险**：长时间自旋浪费 CPU 资源。

------

#### **4. 锁消除（Lock Elimination）**

#### **目标**

移除不必要的同步操作。

#### **原理**

- **逃逸分析**：编译器检测同步对象是否逃逸出当前线程。

- **示例**：

  java

  复制

  ```
  public String concat(String s1, String s2) {
      StringBuffer sb = new StringBuffer(); // 未逃逸出方法
      sb.append(s1);
      sb.append(s2);
      return sb.toString();
  }
  ```

  JVM 会消除 `StringBuffer` 的内部锁。

#### **参数**

```
-XX:+DoEscapeAnalysis     # 启用逃逸分析（默认开启）
-XX:+EliminateLocks       # 启用锁消除（默认开启）
```

#### **5. 锁粗化（Lock Coarsening）**

#### **目标**

减少频繁的锁请求/释放操作。

#### **原理**

将多个相邻的同步块合并为单个更大的同步块。
**示例**：

```
for (int i = 0; i < 1000; i++) {
    synchronized (lock) { // 循环内重复加锁
        // 操作
    }
}
// JVM 优化后：
synchronized (lock) {
    for (int i = 0; i < 1000; i++) {
        // 操作
    }
}
```

#### **适用场景**

- 循环内重复加锁且无竞争。
- **风险**：过度粗化可能增加锁持有时间，引发竞争。

#### **6. 重量级锁（Heavyweight Locking）**

#### **最终保障**

当轻量级锁竞争失败时，膨胀为重量级锁。

#### **原理**

- 通过操作系统互斥量（Mutex）实现线程阻塞。
- 依赖操作系统的线程调度（上下文切换开销大）。

#### **锁优化对比表**

| **优化技术** | **适用场景** | **优点**         | **缺点**               |
| :----------- | :----------- | :--------------- | :--------------------- |
| 偏向锁       | 单线程独占   | 零成本重入       | 多线程竞争时撤销开销大 |
| 轻量级锁     | 低竞争环境   | 避免线程阻塞     | CAS 失败后升级开销     |
| 自旋锁       | 锁持有时间短 | 减少上下文切换   | 自旋过长浪费 CPU       |
| 锁消除       | 对象未逃逸   | 完全去除同步开销 | 依赖逃逸分析准确性     |
| 锁粗化       | 相邻同步块   | 减少锁操作次数   | 可能增加锁竞争概率     |
| 重量级锁     | 高竞争环境   | 保障线程安全     | 上下文切换开销大       |

#### **生产环境调优建议**

1. **监控锁竞争**：

   ```
   jstack <pid>                # 查看线程锁状态
   JFR (Java Flight Recorder)  # 分析锁争用事件
   ```

2. **参数调整**：

   ```
   -XX:+PrintBiasedLockingStatistics  # 偏向锁统计
   -XX:BiasedLockingStartupDelay=0    # 关闭偏向锁延迟（测试用）
   ```

3. **代码级优化**：

   - 使用 `java.util.concurrent` 工具类（如 `ReentrantLock`）替代同步块。
   - 减少锁粒度（如分段锁）。

**总结**:

JVM 的锁优化通过分层策略（偏向→轻量→重量）和编译时优化（锁消除/粗化），在保证线程安全的前提下，最大化降低同步开销。开发者需结合应用场景（竞争程度、锁持有时间）选择同步机制，并借助监控工具持续优化



## 进程与线程

进程与线程是操作系统中实现并发执行的两种基本机制，它们在资源管理、执行效率和通信方式等方面有显著区别。以下是它们的详细对比：

### **1. 基本定义**

- **进程（Process）**
  - 程序的一次执行实例，拥有独立的地址空间、资源（如内存、文件句柄）和系统资源。
  - 操作系统分配资源的最小单位。
  - 进程间相互隔离，一个进程崩溃通常不会影响其他进程。
- **线程（Thread）**
  - 进程内的一个执行单元，共享进程的内存和资源。
  - CPU调度的最小单位。
  - 线程间可直接访问共享数据，但需同步机制避免竞态条件。

### **2. 核心区别**

| **特性**       | **进程**                                                   | **线程**                                                   |
| :------------- | :--------------------------------------------------------- | :--------------------------------------------------------- |
| **资源分配**   | 需分配独立内存和资源，耗时较长                             | 仅需分配栈和寄存器，创建更快                               |
| **调度单位**   | 进程是资源分配的基本单位                                   | 线程是处理器调度的基本单位                                 |
| **上下文切换** | 进程切换涉及内存映射、寄存器等，开销大                     | 线程切换仅需保存少量寄存器状态，效率更高                   |
| **内存空间**   | 独立地址空间                                               | 共享进程地址空间，直接通过内存通信                         |
| **通信方式**   | 通过 **IPC**，如管道、消息队列、共享内存、信号量、套接字等 | 直接共享进程内存，但需同步工具（互斥锁、条件变量、信号量） |
| **独立性**     | 一个进程的崩溃不会影响其他进程                             | 一个线程崩溃可能导致整个进程终止                           |
| **并发性**     | 一个进程只能顺序执行任务                                   | 线程可以并发执行任务，需处理锁竞争                         |
| **适用场景**   | 高隔离性需求；CPU密集型任务（充分利用多核）                | IO密集型任务（高并发）；需要快速响应和资源共享             |

## 线程原理



## 线程池原理

Java线程的创建非常昂贵，需要JVM和OS（操作系统）配合完成大量的工作：

1）必须为线程堆栈分配和初始化大量内存块，其中包含至少1MB的栈内存。

2）需要进行系统调用，以便在OS（操作系统）中创建和注册本地线程。



线程池主要解决了以下两个问题：

1）提升性能：线程池能独立负责线程的创建、维护和分配。在执行大量异步任务时，可以不需要自己创建线程， 而是将任务交给线程池去调度。 线程池能尽可能使用空闲的线程去执行异步任务，最大限度地对已经创建的线程进行复用，使得性能提升明显。

2）线程管理：每个Java线程池会保持一些基本的线程统计信息，例如完成的任务数量、空闲时间等，以便对线程进行有效管理，使得能对所接收到的异步任务进行高效调度。



### JUC 的线程池架构

```java
Executor
	ExecutorService
		AbstractExecutorService
			ThreadPoolExecutor
		ScheduledExecutorService
			ScheduledThreadPoolExecutor

Executors
​	newSingleThreadExecutor() 
​	newFixedThreadPool(int nThreads) 
​	newCachedThreadPool()
​	newScheduledThreadPool()
```

### 线程池参数

1. 核心和最大线程数量

   参数corePoolSize用于设置核心 （Core） 线程池数量， 参数maximumPoolSize用于设置最大线程数量。 线程池执行器将会根据corePoolSize和maximumPoolSize自动地维护线程池中的工作线程， 大

   致的规则为：

   1） 当在线程池接收到的新任务， 并且当前工作线程数少于corePoolSize时， 即使其他工作线程处于空闲状态，也会创建一个新线程来处理该请求，直到线程数达到corePoolSize。

   2）**如果当前工作线程数多于corePoolSize数量，但小于maximumPoolSize数量，那么仅当任务排队队列已满时才会创建新线程**。 通过设置corePoolSize和maximumPoolSize相同， 可以创建一个固定大小的线程池。

   3）当maximumPoolSize被设置为无界值（如Integer.MAXVALUE）时，线程池可以接收任意数量的并发任务。

   4）corePoolSize和maximumPoolSize不仅能在线程池构造时设置， 也可以调用setCorePoolSize() 和setMaximumPoolSize()两个方法进行动态更改。

2. BlockingQueue

​	BlockingQueue（阻塞队列）的实例用于暂时接收到的异步任务，如果线程池的核心线程都在忙，那么所接收到的目标任务缓存在阻塞队列中。

3. keepAliveTime

   线程构造器的keepAliveTime（空闲线程存活时间） 参数用于设置池内线程最大Idle（空闲） 时长或者说保活时长，如果超过这个时间，默认情况下Idle、非Core线程会被回收。如果池在使用过程中提交任务的频率变高， 也可以调用方法setKeepAliveTime(long， TimeUnit)进行线程存活时间的动态调整，可以将时长延长。如果需要防止Idle线程被终止，可以将Idle时间设置为无限大，具体如下：

   setKeepAliveTime(Long.MAXVALUE，TimeUnit.NANOSECONDS);

   默认情况下，Idle超时策略仅适用于存在超过corePoolSize线程的情况。 但是如果调用了 allowCoreThreadTimeOut(boolean)方法，并且传入了参数true，则keepAliveTime参数所设置的Idle超时策略也将被应用于核心线程。

### 向线程池提交任务的两种方式

```java
//Executor 接口中的方法
void execute(Runnable command);

//ExecutorService 接口中的方法
<T> Future<T> submit(Callable<T> task);
<T> Future<T> submit(Runnable task, T result);
Future<?> submit(Runnable task);
```

以上的submit和execute两类方法区别在哪里呢？大致有三点：

（1）**二者所接受的参数不一样**

execute()方法只能接收Runnable类型的参数，而submit()方法可以接收Callable、Runnable两种类型的参数。Callable类型的任务是可以返回执行结果的，而Runnable类型的任务不可以返回执行结果。

Callable是JDK 1.5加入的执行目标接口，作为Runnable的一种补充，允许有返回值，允许抛出异常。 Runnable和Callable的主要区别为： Callable允许有返回值， Runnable不允许有返回值； Runnable不允许抛出异常，Callable允许抛出异常。

（2）**submit()提交任务后会有返回值，而execute()没有**

execute()方法主要用于启动任务的执行， 而任务的执行结果和可能的异常调用者并不关心。 而submit()方法也用于启动任务的执行， 但是启动之后会返回Future对象， 代表一个异步执行实例， 可以通过该异步执行实例去获取结果。

（3）**submit()方便Exception处理**

execute()方法在启动任务的执行后， 任务执行过程中可能发生的异常调用者并不关心。 而通过submit()方法返回Future对象（异步执行实例），可以进行异步执行过程中的异常捕获。

### 线程池的任务调度流程

![img](assets/1710144608816-4eaff6a9-ffda-4d02-82cb-9f8b4dc2d176.png)

1）如果当前工作线程数量小于核心线程池数量，执行器总是优先创建一个任务线程，而不是从线程队列中获取一个空闲线程。

2）如果线程池中总的任务数量大于核心线程池数量，新接收的任务将被加入到阻塞队列中，一直到阻塞队列已满。 在核心线程池数量已经用完、 阻塞队列没有满的场景下， 线程池不会为新任务创建一个新线程。

3）当完成一个任务的执行时，执行器总是优先从阻塞队列中获取下一个任务，并开始执行，一直到阻塞队列为空，其中所有的缓存任务被取光。

4） 在核心线程池数量已经用完、 阻塞队列也已经满了的场景下， 如果线程池接收到新的任务，将会为新任务创建一个线程（非核心线程），并且立即开始执行新任务。

5）在核心线程都用完、阻塞队列已满的情况下，一直会创建新线程去执行新任务，直到池内的线程总数超出maximumPoolSize。如果线程池的线程总数超过maximumPoolSize，线程池就会拒绝接收任务，当新任务过来时，会为新任务执行拒绝策略。

> 在创建线程池时，如果线程池的参数（如核心线程数量、最大线程数量、BlockingQueue等）配置不合理，就会出现任务不能被正常调度的问题。

### ThreadFactory

在调用ThreadFactory的唯一方法newThread()创建新线程时，可以更改创建新线程的名称、线程组、 优先级、 守护进程状态等。 如果newThread()返回值为null， 表示线程工厂未能成功创建线程，线程池可能无法执行任何任务。

使用Executors创建新的线程池时，也可以基于ThreadFactory（线程工厂）创建，在创建新线程池时 可 以 指 定 将 使 用 ThreadFactory 实 例 。 只不过， 如果没有指定的话 ， 就会使用Executors.defaultThreadFactory默认实例。使用默认的线程工厂实例所创建的线程全部位于同一个ThreadGroup（线程组）中，具有相同的NORM PRIORITY（优先级为5），而且都是非守护进程状态。

### 任务阻塞队列

Java中的阻塞队列（BlockingQueue）与普通队列相比有一个重要的特点：在阻塞队列为空时，会阻塞当前线程的元素获取操作。 具体来说， 在一个线程从一个空的阻塞队列中获取元素时线程会被阻塞， 直到阻塞队列中有了元素； 当队列中有元素后， 被阻塞的线程会自动被唤醒 （唤醒过程不需要用户程序干预）。

Java线程池使用BlockingQueue存放接收到的异步任务，BlockingQueue是JUC包的一个超级接口，比较常用的实现类有：

- ArrayBlockingQueue：是一个数组实现的有界阻塞队列 （有界队列） ， 队列中的元素按FIFO 排序。 ArrayBlockingQueue在创建时必须设置大小， 接收的任务超出corePoolSize数量时， 任务被缓存到该阻塞队列中， 任务缓存的数量只能为创建时设置的大小， 若该阻塞队列满， 则会为新的任务创建线程，直到线程池中的线程总数大于maximumPoolSize。

- LinkedBlockingQueue： 是一个基于链表实现的阻塞队列， 按FIFO排序任务， 可以设置容量（有界队列），不设置容量则默认使用Integer.MaxVALUE作为容量（无界队列）。该队列的吞吐量高于ArrayBlockingQueue。

  如果不设置LinkedBlockingQueue的容量（无界队列），当接收的任务数量超出corePoolSize数量时， 则新任务可以被无限制地缓存到该阻塞队列中， 直到资源耗尽。 有两个快捷创建线程池的工厂方法Executors.newSingleThreadExecutor和Executors.newFixedThreadPool使用了这个队列， 并且都

  没有设置容量（无界队列）。

- PriorityBlockingQueue：是具有优先级的无界队列。

- DelayQueue： 这是一个无界阻塞延迟队列， 底层基于PriorityBlockingQueue实现， 队列中每个元素都有过期时间，当从队列获取元素（元素出队）时， 只有已经过期的元素才会出队， 而队列头部的元素是最先过期的元素。 快捷工厂方法Executors.newScheduledThreadPool所创建的线程池使用此队列。

- SynchronousQueue（同步队列） ： 是一个不存储元素的阻塞队列， 每个插入操作必须等到另一个线程的调用移除操作，否则插入操作一直处于阻塞状态，其吞吐量通常高于LinkedBlockingQueue。快捷工厂方法Executors.newCachedThreadPool所创建的线程池使用此队列。与前面的队列相比，这个队列比较特殊，它不会保存提交的任务，而是直接新建一个线程来执行新来的任务。

### 调度器的钩子方法

ThreadPoolExecutor类提供了三个钩子方法（空方法）：

```java
//任务执行之前的钩子方法（前钩子）
protected void beforeExecute(Thread t, Runnable r) { }
//任务执行之后的钩子方法（后钩子）
protected void afterExecute(Runnable r, Throwable t) { }
//线程池终止时的钩子方法（停止钩子）
protected void terminated() { }
```

### 线程池的拒绝策略

在线程池的任务缓存队列为有界队列（有容量限制的队列）的时候，如果队列满了，提交任务到线程池的时候就会被拒绝。总体来说，任务被拒绝有两种情况：

1）线程池已经被关闭。

2）工作队列已满且maximumPoolSize已满。

无论以上哪种情况任务被拒绝， 线程池都会调用RejectedExecutionHandler实例的rejectedExecution()方法。RejectedExecutionHandler是拒绝策略的接口，JUC为该接口提供了以下几种实现：

- AbortPolicy：拒绝策略。使用该策略时， 如果线程池队列满了， 新任务就会被拒绝， 并且抛出RejectedExecutionException异常。该策略是线程池的默认的拒绝策略。

- DiscardPolicy：抛弃策略。如果线程池队列满了，新任务就会直接被丢掉，并且不会有任何异常抛出。

- DiscardOldestPolicy：抛弃最老任务策略。

- CallerRunsPolicy：调用者执行策略。在新任务被添加到线程池时，如果添加失败，那么提交任务线程会自己去执行该任务，不会使用线程池中的线程去执行新任务。
- 自定义策略。

### 线程池的优雅关闭

一般情况下，线程池启动后建议手动关闭。线程池总共存在5种状态，定义在ThreadPoolExecutor类中

```java
private static final int RUNNING = -1 << COUNT_BITS;
private static final int SHUTDOWN = 0 << COUNT_BITS;
private static final int STOP = 1 << COUNT_BITS;
private static final int TIDYING = 2 << COUNT_BITS;
private static final int TERMINATED = 3 << COUNT_BITS;
```

线程池的5种状态具体如下：

1）RUNNING：线程池创建之后的初始状态，这种状态下可以执行任务。

2）SHUTDOWN：该状态下线程池不再接受新任务，但是会将工作队列中的任务执行完毕。

3）STOP：该状态下线程池不再接受新任务，也不会处理工作队列中的剩余任务，并且将会中断所有工作线程。

4）TIDYING：该状态下所有任务都已终止或者处理完成，将会执行terminated()钩子方法。

5）TERMINATED：执行完terminated()钩子方法之后的状态。



线程池的状态转换规则为：

1）线程池创建之后状态为RUNNING。

2）执行线程池的shutdown()实例方法，会使线程池状态从RUNNING转变为SHUTDOWN。

3）执行线程池的shutdownNow()实例方法，会使线程池状态从RUNNING转变为STOP。

4）当线程池处于SHUTDOWN状态，执行其shutdownNow()方法会将其状态转变为STOP。

5）等待线程池的所有工作线程停止，工作队列清空之后，线程池状态会从STOP转变为TIDYING。

6）执行完terminated()钩子方法之后，线程池状态从TIDYING转变为TERMINATED。

优雅地关闭线程池主要涉及的方法有3种：

1）shutdown：是JUC提供一个有序关闭线程池的方法，此方法会等待当前工作队列中的剩余任务全部执行完成之后才会执行关闭，但是此方法被调用之后线程池的状态转变为SHUTDOWN，线程池不会再接收新的任务。

2）shutdownNow：是JUC提供一个立即关闭线程池的方法，此方法会打断正在执行的工作线程，并且会清空当前工作队列中的剩余任务，返回的是尚未执行的任务。

3） awaitTermination： 等待线程池完成关闭。在调用线程池的shutdown()与shutdownNow()方法时， 当前线程会立即返回， 不会一直等待直到线程池完成关闭。 如果需要等到线程池关闭完成， 可以调用awaitTermination()方法。

### 如何判断线程池已经全部执行完

判断线程池中的任务是否执行完的方法有很多，比如以下几个：

1. 使用 getCompletedTaskCount() 统计已经执行完的任务，和 getTaskCount() 线程池的总任务进行对比，如果相等则说明线程池的任务执行完了，否则既未执行完。
2. 使用 FutureTask 等待所有任务执行完，线程池的任务就执行完了。
3. 使用 CountDownLatch 或 CyclicBarrier 等待所有线程都执行完之后，再执行后续流程。

### 注册 JVM 钩子函数自动关闭线程池

如果使用了线程池，可以在JVM注册一个钩子函数，在JVM进程关闭之前，由钩子函数自动将线程池优雅关闭，以确保资源正常释放。

### Executors 快捷创建线程池的潜在问题

在很多公司（如阿里、华为等）的编程规范中，非常明确地禁止使用Executors快捷创建线程池， 为什么呢？这里从源码讲起， 介绍使用Executors工厂方法快捷创建线程池将会面临的潜在问题。

1. 使用 Executors 创建“固定数量的线程池”的潜在问题

   ```java
   public static ExecutorService newFixedThreadPool(int nThreads){
     return new ThreadPoolExecutor(
       nThreads, // 核心线程数
       nThreads, // 最大线程数
       0L, // 线程最大空闲（Idle）时长
       TimeUnit.MILLISECONDS, // 时间单位：毫秒
       new LinkedBlockingQueue<Runnable>() // 任务的排队队列，无界队列
     );
   }
   ```

newFixedThreadPool工厂方法返回一个ThreadPoolExecutor实例，该线程池实例的corePoolSize数量为参数 nThread ， 其 maximumPoolSize 数量也为 参数 nThread ， 其 workQueue 属性的值为`LinkedBlockingQueue<Runnable>()`无界阻塞队列。

使用Executors创建的“固定数量的线程池”的潜在问题主要存在于其workQueue上，其值为LinkedBlockingQueue（无界阻塞队列）。如果任务提交速度持续大于任务处理速度，就会造成队列中大量的任务等待。如果队列很大，很有可能导致JVM出现OOM异常，即内存资源耗尽。

2. 使用 Executors 创建“单线程化线程池”的潜在问题

   ```java
   public static ExecutorService newSingleThreadExecutor(){
     return new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(
       1, // 核心线程数
       1, // 最大线程数
       0L, // 线程最大空闲（Idle）时长
       TimeUnit.MILLISECONDS, // 时间单位：毫秒
       new LinkedBlockingQueue<Runnable>() // 无界队列
     ));
   }
   ```

​	使用Executors创建的“单线程化线程池”与“固定大小线程池”一样，其潜在问题仍然存在与其workQueue属性上，该属性的值为LinkedBlockingQueue（无界阻塞队列）。如果任务提交速度持续大于任务处理速度， 就会造成队列大量阻塞。 如果队列很大， 很有可能导致JVM的OOM异常，甚至造成内存资源耗尽。

3. 使用 Executors 创建“可缓存线程池”的潜在问题

   ```java
   public static ExecutorService newCachedThreadPool(){
     return new ThreadPoolExecutor(
       0, //核心线程数
       Integer.MAXV_ALUE, //最大线程数
       60L, //线程最大空闲（Idle）时长
       TimeUnit.MILLISECONDS, //时间单位：毫秒
       new SynchronousQueue<Runnable>() //任务的排队队列，无界队列
     );
   }
   ```

   以上代码通过调用ThreadPoolExecutor标准构造器创建一个核心线程数为0、 最大线程数不设限制的线程池。所以，理论上“可缓存线程池”可以拥有无数个工作线程，即线程数量几乎无限制。“可缓存线程池”的workQueue为SynchronousQueue同步队列，这个队列类似于一个接力棒，入队与出队必须同时传递，正因为 “可缓存线程池”可以无限制创建线程， 不会有任务等待，所以才使用SynchronousQueue。

   当“可缓存线程池”有新任务到来时，新任务会被插入到SynchronousQueue实例中，由于SynchronousQueue是同步队列， 因此会在池中寻找可用线程来执行， 若有可用线程则执行， 若没有可用线程，则线程池会创建一个线程来执行该任务。

   SynchronousQueue是一个比较特殊的阻塞队列实现类， SynchronousQueue没有容量， 每一个插入操作都要等待对应的删除操作， 反之每个删除操作都要等待对应的插入操作。 也就是说， 如果使用SynchronousQueue， 提交的任务不会被真实地保存， 而是将新任务交给空闲线程执行， 如果没有空闲线程， 就创建线程， 如果线程数都已经大于最大线程数， 就执行拒绝策略。 使用这种队列需要将maximumPoolSize设置得非常大，从而使得新任务不会被拒绝。使用Executors创建的“可缓存线程池”的潜在问题存在于其最大线程数量不设上限。由于其maximumPoolSize的值 Integer.MAX_VALUE（非常大） ，可以认为是无限创建线程的， 如果任务提交较多，就会造成大量的线程被启动，很有可能造成OOM异常，甚至导致CPU线程资源耗尽。

4. 使用 Executors 创建“可调度线程池”的潜在问题

   ```java
   public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize){
   	return new ScheduledThreadPoolExecutor(corePoolSize);
   }
   
   public ScheduledThreadPoolExecutor(int corePoolSize){
       super(corePoolSize, // 核心线程数
       Integer.MAX_VALUE, // 最大线程数
       0, // 线程最大空闲（Idle）时长
       NANOSECONDS, // 时间单位
       new DelayedWorkQueue() // 任务的排队队列
     );
   }
   ```

使用Executors创建的“可调度线程池”的潜在问题存在于其最大线程数量不设上限。由于其线程数量不设限制， 如果到期任务太多， 就会导致CPU的线程资源耗尽。 

“可调度线程池”的潜在问题首先还是无界工作队列（任务排队的队列）长度都为 Integer.MAX_VALUE，可能会堆积大量的任务，从而导致OOM甚至耗尽内存资源的问题。

总结起来，使用Executors去创建线程池主要的弊端如下：

（1）FixedThreadPool和SingleThreadPool这两个工厂方法所创建的线程池，工作队列 （任务排队的队列）长度都为Integer.MAX_VALUE， 可能会堆积大量的任务，从而导致OOM（即耗尽内存资源）。

（2）CachedThreadPool和ScheduledThreadPool 这两个工厂方法所创建的线程池允许创建的线程数量为Integer.MAX_VALUE，可能会导致创建大量的线程，从而导致OOM问题。

### 确定线程池的线程数

（1）IO密集型任务：

- 核心线程数 corePoolSize 为：CPU核数*2，corePoolSize和maximumPoolSize 保持一致
- allowCoreThreadTimeOut 为 true
- 使用有界队列缓冲任务而不是无界队列

（2）CPU密集型任务

- 核心线程数 corePoolSize 为：CPU核数，corePoolSize和maximumPoolSize 保持一致
- allowCoreThreadTimeOut 为 true
- 使用有界队列缓冲任务而不是无界队列

（3）混合型任务。此类任务既要执行逻辑计算，又要进行IO操作（如RPC调用、数据库访问）。相对来说，由于执行IO操作的耗时较长 （一次网络往返往往在数百毫秒级别） ， 这类任务的CPU利用率也不是太高。Web服务器的HTTP请求处理操作为此类任务的典型例子。

在为混合型任务创建线程池时，如何确定线程数呢？业界有一个比较成熟的估算公式，具体

如下：

最佳线程数= （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU核数

经过简单的换算，以上公式可进一步转换为：

最佳线程数目=（线程等待时间与线程CPU时间之比 + 1）* CPU核数



比如在Web服务器处理HTTP请求时，假设平均线程CPU运行时间为100毫秒，而线程等待时间（比如包括DB操作、RPC操作、缓存操作等）为900毫秒，如果CPU核数为8，那么根据上面这个公式，估算如下：

（900ms+100ms）/100ms * 8= 10*8 = 80

